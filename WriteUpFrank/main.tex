\documentclass[a4paper, 12pt, titlepage, bibtotoc]{scrartcl} %scrartcl für kurze Artikel

\renewcommand*\sectfont{\normalcolor\rmfamily\bfseries}
\renewcommand*\descfont{\rmfamily\bfseries}
\setkomafont{dictum}{\normalfont\normalcolor\rmfamily\small}

\makeatletter% siehe De-TeX-FAQ
\renewcommand*{\toc@heading}{%
  \addsec{\contentsname}% bei scrartcl \addsec statt \addchap
  \@mkboth{\contentsname}{\contentsname}%
}
\makeatother% siehe \makeatletter

\usepackage[ngerman]{babel}
\usepackage[ansinew]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{color}
% \usepackage{courier} % Monospace/Truetype umstellen
\usepackage{enumitem} % \begin{enumerate}[label={\alph*)}] \item \end{enumerate} für a) b) c)...
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{setspace}
\usepackage{ulem}
	\normalem %stellt emph{} wieder auf kursiv, sonst unterstrichen
\usepackage{graphicx}
\graphicspath{{img/}}
\usepackage[hmargin={3cm,3cm}, vmargin={2.5cm, 3.5cm}]{geometry}
% \usepackage{times}
\usepackage{mathptmx}
\usepackage{nicefrac} 	
\usepackage{tikz}
\usepackage{tabularx}
\usepackage{scalefnt}
\usepackage{titlesec}
\titlespacing{\section}{0pt}{*2.5}{*1.5}
\titlespacing{\subsection}{0pt}{*2}{*1}
\titlespacing{\subsubsection}{0pt}{*1}{*0.5}

\tolerance=500

\usepackage{url}
\urlstyle{leo}

\DeclareMathOperator*{\argmax}{\text{arg\,max}}

%\usepackage{hyperref}
\usepackage{csquotes}
\usepackage{parcolumns}

\bibliography{literature}
\usepackage[style=authoryear]{biblatex} 
\addbibresource{literature.bib}

\DefineBibliographyStrings{ngerman}{
    references = {Literaturverzeichnis}
}

\defbibenvironment{bibliography}
{\list{}
{\setlength{\leftmargin}{\bibhang}%
\setlength{\itemindent}{-\leftmargin}%
\setlength{\itemsep}{12px}%
\setlength{\parsep}{\bibparsep}}}
{\endlist}
{\item}

% \renewbibmacro*{cite:year+labelyear}{%
% \iffieldundef{year}
% {}
% {\printtext[bibhyperref]{%
% \mkbibparens{%
% \printfield{year}%
% \printfield{labelyear}}}}}


%%%% Klammern um die Jahreszahl 
% \renewbibmacro*{cite:labelyear+extrayear}{%
% \iffieldundef{labelyear}
% {}
% {\printtext[bibhyperref]{%
% \mkbibparens{\iffieldundef{origyear}{}{\printfield{origyear}\addslash}% <--- added
% \printfield{labelyear}%
% \printfield{extrayear}}}}}
% 
% \renewbibmacro*{date+extrayear}{%
% \iffieldundef{year}
% {}
% {\printtext[parens]{%
% \iffieldundef{origyear}{}{\printfield{origyear}\addslash}%<--- added
% \printdateextra}}}

%Schriftart http://tu-dresden.de/Members/jan.rudl/latex_win/fonts.pdf
%\usepackage[T1]{fontenc}
%\newcommand{\changefont}[3]{
%\fontfamily{#1} \fontseries{#2} \fontshape{#3} \selectfont}

% \setlength{\tabcolsep}{5pt} %colspan
% \renewcommand{\arraystretch}{1.3} %rowspan

\usepackage{parskip}

\begin{document}

\input{inc.title.tex}

% \setcounter{page}{0}\clearpage\newpage
\renewcommand{\baselinestretch}{1.25}\normalsize


\pagenumbering{Roman} \setcounter{page}{2}
\addcontentsline{toc}{section}{Inhaltsverzeichnis}
\tableofcontents

\renewcommand{\baselinestretch}{1.50}\normalsize

\newpage

\section*{Abkürzungsverzeichnis}
\addcontentsline{toc}{section}{Abkürzungsverzeichnis}

\begin{tabular}{ll}
CSV & Comma-Separated Value\\
GSM & Global System for Mobile Communications\\
GPS & Global Positioning System\\
ML & Maximum Likelihood\\
UMTS & Universal Mobile Telecommunications System
\end{tabular}

\newpage

\addcontentsline{toc}{section}{Abbildungsverzeichnis}
\listoffigures

\newpage

\listoftables
\addcontentsline{toc}{section}{Tabellenverzeichnis}

\newpage

\pagenumbering{arabic} \setcounter{page}{1}

\section{Einleitung}

Computer sind heutzutage allgegenwärtig. Viele Menschen besitzen mobile Geräte, die stationären Computern in Sachen Rechenleistung nur noch in wenig nachstehen. Der wirtschaftliche Nutzen des sogenannten "`ubiquitous computing"' ist vielseitig. Durch eine zeitaktuelle und genaue Positionsbestimmung könnten beispielsweise Restaurantbesitzer besondere Mittagsangebote auf das Smartphone der potenziellen Kunden senden, die noch unentschlossen vor ihrem Lokal stehen.

Könnte man vorhersehen, wo sich die Anwender zukünftig hinbewegen, so könnten Angebote schon im Vorfeld unterbreitet oder Informationen verschickt werden. Man nennt dieses Forschungsfeld \emph{Trajectory-Mining} (dt. Finden von Bewegungsmustern). In der Literatur finden sich unterschiedliche Ansätze zum Finden und Vorhersagen von Bewegungsmustern.

Unterschiede in den Methoden ergeben sich beispielsweise in der Repräsentation der Ortskoordinaten. Viele Ansätze rastern die Koordinaten nach festen Kriterien.\footnote{Vgl.~\textcite{peng2003developing}; Vgl.~\textcite{ishikawa2004extracting}; Vgl.~\textcite{verhein2006mining}} Offen ist dabei die Frage nach der Rastergenauigkeit. Zu große Raster sind ungenau, zu kleine Raster enthalten eventuell zu wenige Beobachtungen. Abhilfe kann das Clustering der Koordinaten schaffen.\footnote{Vgl.~\textcite{jeung2007mining}} Ein anderer Ansatz speichert die Bewegungsmuster in sogenannten Trajectory-Pattern-Trees und wählt zur Bewegungsvorhersage das Muster des Baumes mit der höchsten Punktzahl.\footnote{Vgl.~\textcite{monreale2009wherenext}}  Weiterhin wurde der Nutzen der Kombination von geographischen und semantischen Merkmalen zur Vorhersage untersucht.\footnote{Vgl.~\textcite{ying2011semantic}}

Ziel des Projekts ist es, eine Handyanwendung zu programmieren, welche die nötigen Daten für eine verlässliche Positionsvorhersage sammelt, und diese auszuwerten. Somit soll untersucht werden, mit welcher Genauigkeit Bewegungen von Menschen vorhergesagt werden können. Im Rahmen dieser Arbeit liegt der Fokus auf der Positionsvorhersage. Die entwickelte Handyanwendung wird in einer anderen Arbeit näher beschrieben.\footnote{Vgl.~\textcite{bar2013android}}

Zur Entwicklung der Handyanwendung wurde das \emph{Android-Software-Development-Kit}\footnote{\emph{http://developer.android.com/sdk/index.html}}, zur Datenaufbereitung und statistischen Analyse die Programmiersprachen \emph{Java} und \emph{R} verwendet. Die Visualisierung fand mit Hilfe von \emph{R} und \emph{Google Maps}\footnote{\emph{http://maps.google.de}} statt.

Im ersten Abschnitt der Arbeit findet sich eine Beschreibung der eingesetzten Methoden zur Datensammlung und Datenanalyse. Hierbei wird vor allem auf die zur Positionsvorhersage verwendeten Modelle eingegangen. Der zweite Teil stellt die gesammelten Daten vor und die Ergebnisse der Analyse und Vorhersage. Abschließend folgt eine Zusammenfassung, eine kritische Würdigung und ein Ausblick auf zukünftige Forschungsarbeit.

\newpage

\section{Methoden}
\subsection{Datenerhebung und -vorerarbeitung}
\label{subsec:data_collection}

Um Daten zur anschließenden Auswertung zu sammeln, wurde die Android-Anwendung \emph{AndroidDataCollection}\footnote{Quellcode und Dokumentation finden sich auf \emph{https://github.com/FRSB/AndroidDataCollection}.} entwickelt. Auf dem Mobiltelefon installiert, zeichnet sie minütlich Daten verschiedener Sensoren und Schnittstellen auf und speichert diese lokal in einer Datei. Für die in Abschnitt~\ref{subsec:analysis} beschriebenen Analysen sind folgende Informationen relevant: (1) Mobilfunkzellen-ID der aktuell verwendeten Zelle (GSM oder UMTS) und (2) Position des Mobiltelefons\footnote{Die Positionsbestimmung findet hierarchisch statt. Zunächst wird versucht, die ungefähre Position über die aktuell verwendete Mobilfunkzelle zu ermitteln. Falls ein Drahtlosnetzwerk zur Verfügung steht über das hinreichend genaue Positionsdaten verfügbar sind, wird die Position aktualisiert. Sollte das GPS-Signal anliegen und stark genug sein, überschreibt es die ungefähren Positionsdaten. So wird der API die bestmögliche Position übergeben. Nähere Informationen finden sich im Android Developers API Guide unter \emph{http://developer.android.com/guide/topics/location/strategies.html}.}.

Nach einer gewissen Zeit wird das Mobiltelefon über USB mit dem Computer verbunden und die gesammelten Daten in Form einer CSV-Datei übertragen. Damit aus den minütlich aufgezeichneten Positionsdaten eine Bewegungsvorhersage möglich ist, muss zunächst eine Datenaufbereitungen und -transformationen stattfinden. So werden fehlerhaft aufgezeichnete Datensätze und Aufzeichnungen ohne bestimmbare Mobilfunkzellen-ID entfernt. Anschließend folgen zwei Vorverarbeitungsschritte unabhängig voneinander: Extrahieren der Bewegungen und Schätzung der Mobilfunkzellenpositionen.

\begin{description}
\item[Extrahieren der Bewegungen.] Hierfür werden die zeitlich aufeinanderfolgende Aufzeichnungen, bei denen sich die Mobilfunkzellen-ID nicht ändert, entfernt. So bleibt eine Folge von Zellenübergängen übrig, die später zur Vorhersage verwendet werden kann.
\item[Schätzung der Mobilfunkzellenpositionen.] Um die aufgezeichneten Bewegungen visualisieren zu können, wird zu jeder gesehenen Mobilfunkzelle eine ungefähre Position bestimmt. Dies geschieht, indem die Daten nach Mobilfunkzelle gruppiert und anschließend die jeweils gemessenen Positionen des Mobiltelefons gemittelt werden. So entsteht eine Zuordnung von Mobilfunkzellen zu Positionen.
\end{description}

\subsection{Datenanalyse}
\label{subsec:analysis}

\subsubsection*{Modellbildung}

Die Bewegungen eines Mobiltelefonnutzers werden als zeitdiskreter stochastischer Prozess modelliert. Sei der Beobachtungszeitraum $T = \{0,\ldots,n\}$ und der Zustandsraum $S = \{1, \ldots, m\}$. Ein Nutzer $u$ befindet sich zum Zeitpunkt $t \in T$ im Zustand $x_t \in S$. Ein Zustand entspricht der Mobilfunkzelle, an welcher der Nutzer angemeldet ist. Eine Bewegung von einer Mobilfunkzelle zur nächsten entspricht somit einer diskreten Zustandsänderung von $x_t$ zu $x_{t+1}$. Jeder Zustandsänderung wird eine Wahrscheinlichkeit in Abhängigkeit der vergangenen Zustände zugeordnet. Solche Modelle werden Markov-Modelle genannt.\footnote{Vgl.~\textcite{bishop2006pattern},~S.~607~ff.} In den folgenden Absätzen sollen die zur Vorhersage verwendeten Modelle vorgestellt werden.

Will man die nächste Position eines Nutzers vorhersagen, erscheint es nützlich, dies in Abhängigkeit der aktuellen Position zu tun. Das entstehende Markov-Modell ist eine Markov-Kette erster Ordnung. Unter der Annahme stationärer Übergangswahrscheinlichkeiten\footnote{Hängt die Wahrscheinlichkeit $p(x_{t+1}|x_{t})$ für den Übergang von $x_t$ nach $x_{t+1}$ nicht von $t$ ab, spricht man von sogenannten stationären Übergangswahrscheinlichkeiten. Es spielt für den Übergang also keine Rolle an welchem Zeitpunkt er stattfindet. Markov-Ketten mit stationären Übergangswahrscheinlichkeiten nennt man homogen. Vgl.~hierzu \textcite{ouvrard2009probabilites}, S.~411.} lässt sich das Modell mit Hilfe eines Transitionsdiagramms und der zugehörigen Transitionsmatrix beschreiben. Exemplarisch ist ist in Abbildung~\ref{img:transitions} ein Transitionsdiagramm für eine Markov-Kette erster Ordnung mit drei unterschiedlichen Zuständen dargestellt. Die zugehörigen Übergangswahrscheinlichkeiten werden in einer Transitionsmatrix der Form
\begin{equation}
\mathbf{A}=\begin{bmatrix}
A_{11} & A_{12} & A_{13} \\
A_{21} & A_{22} & A_{23} \\
A_{31} & A_{32} & A_{33}
\end{bmatrix}
\end{equation}
dargestellt, wobei $A_{ij} = p(x_{t+1} = j | x_t=i)$ der Wahrscheinlichkeit für den Zustandsübergang von $x=i$ nach $x=j$ entspricht. Zusätzlich müssen die Übergangswahrscheinlichkeiten in $\mathbf{A}$ zeilenweise die Bedingungen an eine Wahrscheinlichkeitsverteilung erfüllen:
\begin{equation}
\forall i,j \in S: A_{ij} \geq 0,
\end{equation}
\begin{equation}
\forall i\in S: \sum_{j\in S} A_{ij} = 1.
\end{equation}

\begin{figure}[t]
	\centering
	\begin{tabular}{@{}r@{}}
		\scalebox{.6}{%
			\scalefont{2}
			\input{img/transition_chart.tex}
			}\\
		\footnotesize Quelle: In Anlehnung an \textcite{bishop2006pattern}, S.~611
	\end{tabular}

	\caption[Transitionsdiagramm einer Markov-Kette erster Ordnung]{Transitionsdiagramm einer Markov-Kette erster Ordnung. Die Wahrscheinlichkeiten für einen Zustandsübergang von $x=i$ nach $x=j$ werden durch das Element $A_{ij}$ der zugehörigen Transitionsmatrix ausgedrückt.}
	\label{img:transitions}
\end{figure}

Das gerichtete graphische Modell einer Markov-Kette ist in Abbildung~\ref{img:graphical_model} dargestellt. Die Verbundverteilung der beobachteten Zustände $p(x_0, \ldots x_n)$ faktorisiert entsprechend der Unabhängigkeitsannahmen in
\begin{equation}
p(x_0, \ldots, x_n) = p(x_0) \prod\limits_{t=1}^{n}p(x_t | x_{t-1}).
\end{equation}
Die Parameter des Modells sind zum einen die Transitionsmatrix $\mathbf{A}$, welche alle bedingten Wahrscheinlichkeiten enthält, sowie zum anderen der Vektor $\vec \pi$  mit $\pi_i = p(x_0 = i)$, welcher die Wahrscheinlichkeiten für die Startzustände angibt.


\begin{figure}
	\centering
	\scalebox{.8}{%
	\scalefont{2}
	\input{img/graphical_model.tex}
	}
	\caption[Graphisches Modell einer Markov-Kette erster Ordnung]{Graphisches Modell einer Markov-Kette erster Ordnung. Der Zustand zum nachfolgenden Zeitpunkt hängt nur vom aktuellen Zustand ab.}
	\label{img:graphical_model}
\end{figure}

Markov-Ketten erster Ordnung treffen starke Unabhängigkeitsannahmen. Soll bei der Vorhersage nicht nur die direkte Vergangenheit betrachtet werden, sondern weiter zurückblicken, müssen diese Annahmen abgeschwächt werden. Es ergeben sich Markov-Ketten höherer Ordnung. Entsprechend erhöht sich die Anzahl der Parameter des Modells. So berücksichtigt eine Markov-Kette zweiter Ordnung beim Vorhersagen von $x_{t+1}$ die Zustände $x_{t}$ und $x_{t-1}$. Die stationären Übergangswahrscheinlichkeiten einer Markov-Kette $d$-ter Ordnung können in einem $d+1$-dimensionalen Tensor repräsentiert werden.

\subsubsection*{Parameterschätzung und Vorhersage}

Zur Schätzung der Transitionsmatrix homogener Markov-Ketten erster Ordnung kann ein Maximum-Likelihood-Schätzer (ML) verwendet werden. Sei $N_{ij}$ die Anzahl der beobachteten Zustandsübergänge von Zustand $i$ nach Zustand $j$, dann ist der ML-Schätzer $\mathbf{\hat A}$ für die Transitionsmatrix gegeben als\footnote{Vgl.~\textcite{murphy2012machine},~S.~593.}
\begin{equation}
\hat A_{ij} = \frac{N_{ij}}{\sum_{j}N_{ij}}.
\end{equation}
Bei gegebenem Zustand $x_{t} = i$ kann zur Vorhersage des nächsten Zustandes $\hat x_{t+1}$ der mit der größten Transitionswahrscheinlichkeit von $i$ ausgehend gewählt werden:
\begin{equation}
\hat x_{t+1} = \argmax_j\ \hat A_{ij},\quad x_{t} = i
\end{equation}
Der Parameter $\vec \pi = p(x_0)$ ist bei der Vorhersage unerheblich, sofern bereits eine Position bekannt ist. Er wird deshalb nicht geschätzt.

Die Schätzer für die Transitionswahrscheinlichkeiten der Markov-Ketten höherer Ordnung sowie die zugehörige Vorhersagegleichung sind in Tabelle~\ref{tab:markov} dargestellt. Die Anzahl der Parameter (Elemente der Transitionsmatrix bzw. des Transitionstensors) wächst mit steigender Ordnung exponentiell.\footnote{Je weiter in die Vergangenheit geschaut wird, desto mehr Kombinationen von Zustandsübergängen gibt es. Da für jede Kombination der Ausgangszustände die Summe der Übergangswahrscheinlichkeiten zu 1 summieren muss, werden nur $m^k \cdot (m-1)$ und nicht $m^{k+1}$ Parameter benötigt.} Die Herleitung der Schätzer findet sich in Anhang A.

\renewcommand{\arraystretch}{1.2}
\begin{table}[t]
\centering
\begin{tabular}{m{3cm}m{3.5cm}m{3cm}m{3.6cm}}
\textbf{Modell} & \textbf{Anzahl Parameter} & \textbf{Schätzer} & \textbf{Vorhersage}\\
\hline
Markov-Kette erster Ordnung & $m \cdot (m - 1)$ & $\hat A_{ij} = \frac{N_{ij}}{\sum_{j}N_{ij}}$ & $\hat x_{t+1} = \argmax_j\ \hat A_{ij}$\\
Markov-Kette zweiter Ordnung & $m^2 \cdot (m - 1)$ & $\hat A_{ijk} = \frac{N_{ijk}}{\sum_{k}N_{ijk}}$ & $\hat x_{t+1} = \argmax_k\ \hat A_{ijk}$\\
Markov-Kette dritter Ordnung & $m^3 \cdot (m - 1)$ & $\hat A_{ijkl} = \frac{N_{ijkl}}{\sum_{l}N_{ijkl}}$ & $\hat x_{t+1} = \argmax_l\ \hat A_{ijkl}$
\end{tabular}
\caption{Eigenschaften von Markov-Ketten verschiedener Ordnung}
\label{tab:markov}
\end{table}

\newpage

\section{Experimente}

\subsection{Datensätze}

\newcommand{\SB}{SB}
\newcommand{\MB}{MB}

Während des Projekts wurden mit Hilfe der in Abschnitt~\ref{subsec:data_collection} vorgestellten Software von zwei freiwillig teilnehmenden Mobilfunknutzern innerhalb eines Monats Daten gesammelt. Tabelle~\ref{tab:datasets} zeigt die Anzahl der besuchten Mobilfunkzellen (Zustände), die Anzahl der beobachteten Zustandsübergänge und die Häufigkeitsverteilung der beobachteten Zustände der zwei gewonnenen Datensätze nach der Vorverarbeitung. Datensatz \SB\ beinhaltet weniger Zustände und Beobachtungen als Datensatz \MB, ist jedoch auch weniger steil ($\omega_{\text{\SB}} = 22{,}4$ und  $\omega_{\text{\MB}} = 69{,}13$).\footnote{Die relative Kurtosis $\omega$ einer Verteilung ist ein Maß für die Steilheit. Eine sehr steile Verteilung weist die Wahrscheinlichkeitsmasse hauptsächlich einigen wenigen, extremen Ereignissen zu. Die relative Kurtosis der Standardnormalverteilung beträgt $\omega_{\mathcal N(0,1)} = 3$. Näheres hierzu findet sich in \textcite{assenmacher2003deskriptive},~S.~114~ff.}

\vspace*{0.5em}
\renewcommand{\arraystretch}{1.4}
\newcolumntype{R}[1]{>{\raggedright\arraybackslash}m{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash}m{#1}}
\begin{table}[h]
\centering
\begin{tabular}{m{2cm}C{2.5cm}C{3cm}C{5cm}@{}}
\textbf{Datensatz} & \textbf{Anzahl Zustände} & \textbf{Anzahl Beobachtunge\-n} & \textbf{Häufigkeitsverteilung\newline der Zustände}\\
\hline
\SB & 78 & 603 & \includegraphics*[width=5cm, trim=2cm 2cm 1.5cm 1cm]{sb_cell_table}\\
\MB & 156 & 1533 &  
\includegraphics*[width=5cm, trim=2cm 2cm 1.5cm 1.5cm]{mb_cell_table}
\end{tabular}
\caption{Metadaten der zwei gesammelten Datensätze}
\label{tab:datasets}
\end{table}

Um einen besseren Eindruck der aufgezeichneten Bewegungsmuster zu erhalten, wurden die gesammelten Mobilfunkzellenkoordinaten grafisch aufbereitet. Abbildung~\ref{img:locations} zeigt die geschätzten Koordinaten der Mobilfunkzellen an denen der Benutzer in Datensatz \SB\ angemeldet war. In Abbildung~\ref{img:map} wurden die Koordinaten auf eine Landkarte übertragen.

Auffällig ist die Häufung der Zellen zwischen Halle (Saale) und Bitterfeld-Wolfen. Hier ist offenbar das gewohnte Bewegungsumfeld des Nutzers. Die Vorhersage sollte in diesen Gebieten sinnvoll und möglich sein. Es ist zu erwarten, dass einmalig besuchte Zellen (zum Beispiel alle westlich von 11.9° östliche Breite befindliche) nicht gut vorhersagbar sind.

\begin{figure}[p]
\begin{center}
\includegraphics*[width=1\linewidth]{cell_locations}
\caption[Koordinaten der \SB-Mobilfunkzellen]{Längen- und Breitengradkoordinaten der im Datensatz \SB\ beobachteten Mobilfunkzellen. Dargestellt sind jeweils die geschätzten Positionen der Mobilfunkzellen, an welcher der Benutzer angemeldet war.}
\label{img:locations}
\end{center}
\end{figure} 

\begin{figure}[p]
\begin{center}
\includegraphics*[width=.9\linewidth]{map.png}
\caption[Karte der \SB-Mobilfunkzellen]{Übertragung der im Datensatz \SB\ beobachteten Mobilfunkzellenkoordinaten aus Abbildung~\ref{img:locations} auf eine Landkarte.}
\label{img:map}
\end{center}
\end{figure} 

\subsection{Untersuchung der Vorhersagegenauigkeit}

Um die nächste Position eines Nutzers mit Hilfe eines Markov-Modells vorherzusagen, wird die entsprechende in Tabelle~\ref{tab:markov} beschriebene Entscheidungsregel wie angewendet. Hierfür ist jedoch ein hinreichend genauer Schätzer der Transitionswahrscheinlichkeiten notwendig. Dieser könnte beispielsweise mittels Online-Learning direkt auf dem Mobiltelefon errechnet werden. So werden Vorhersagen mit der Zeit immer genauer und das Vorhersagemodell lernt mit der Zeit.

Um festzustellen, wie gut diese Methode in der Praxis funktionieren kann, wurden auf den zwei gesammelten Datensätzen jeweils Markov-Ketten unterschiedlicher Ordnung trainiert und die Vorhersagegenauigkeit gemessen. Die Vorhersagegenauigkeit $\text{PA}(\hat x_{t+1})$ für eine konkrete Vorhersage $\hat x_{t+1}$, gegeben der wahren Position $x_{t+1}$ wird definiert als
\begin{align}
\text{PA}(\hat x_{t+1}) = \text{PA}_{t+1} = \mathbb{I}(\hat x_{t+1} = x_{t+1}),
\end{align}
wobei $\mathbb{I}(X)$ den Wahrheitswert einer aussagenlogischen Formel $X$ in $1$ bzw. $0$ kodiert:
\begin{align}
\mathbb{I}(X) = \begin{cases}
  1,  & \text{wenn }X\text{ wahr,}\\
  0, & \text{sonst.}
\end{cases}
\end{align}

Für die Vorhersage des Zustandes zum Zeitpunkt $t+1$ werden alle Beobachtungen $x_i,\ i \leq t$ zur Schätzung der Parameter verwendet, und anschließend überprüft, ob die Vorhersage korrekt war. Bei korrekter Vorhersage ist die Genauigkeit 1, sonst 0.

Damit die Ergebnisse möglichst nah an das Szenario des Online-Learning herankommen, wurden die Modelle mit den ersten beobachteten Daten beginnend, sukzessiv evaluiert und der Schätzer verbessert. Dabei wurde die Vorhersagegenauigkeit kumuliert und gemittelt. Mit Hilfe der sukzessiv berechneten Vorhersagegenauigkeiten $\text{PA}_1,\ldots,\text{PA}_n$ der beobachteten Zustände $x_1,\ldots,x_n$, lässt sich die mittlere Vorhersagegenauigkeit bis zum Zeitpunkt $T$ berechnen:
\begin{align}
\overline{\text{PA}}_T = \frac{1}{T} \cdot \sum\limits_{i=1}^{T} \text{PA}_i.
\end{align}
Das Vorgehen ist in Abbildung~\ref{img:eval_approach} dargestellt. Zu Beginn wird die Vorhersagegenauigkeit relativ schlecht sein. Das Modell hat noch nicht viele Zustandsübergänge beobachtet und macht entsprechend viele Fehler. Nach einer Einschwingphase stabilisiert sich die durchschnittliche Vorhersagegenauigkeit.

\begin{figure}[t]
\begin{center}
	\scalebox{1}{%
		\scalefont{1}
		\input{img/evaluation.tex}
	}
	\caption{Online-Evaluation der Vorhersagegenauigkeit.}
	\label{img:eval_approach}
\end{center}
\end{figure}

Im Rahmen der Experimente wurde die beschriebene Evaluation auf den gesammelten Daten \SB\ und \MB\ durchgeführt. Die mittlere Vorhersagegenauigkeit in Abhängigkeit der beobachteten Zustandsübergänge ist in Abbildung~\ref{img:accuracy_sb} für \SB, beziehungsweise Abbildung~\ref{img:accuracy_mb} für \MB\ dargestellt. Es wurden Markov-Ketten erster, zweiter und dritter Ordnung verwendet.

\begin{figure}[p]
\begin{center}
\includegraphics*[width=.9\linewidth]{prediction_accuracy_sb}
\caption[Durchschnittliche Vorhersagegenauigkeit des Datensatzes \SB]{Durchschnittliche Vorhersagegenauigkeit Markov-Ketten erster, zweiter und dritter Ordnung auf den Daten des Datensatzes \SB.}
\label{img:accuracy_sb}
\end{center}
\end{figure}

\begin{figure}[p]
\begin{center}
\includegraphics*[width=.8975\linewidth]{prediction_accuracy_mb}
\caption[Durchschnittliche Vorhersagegenauigkeit des Datensatzes \MB]{Durchschnittliche Vorhersagegenauigkeit Markov-Ketten erster und zweiter Ordnung auf den Daten des Datensatzes \MB. Die Markov-Ketten dritter Ordnung wurden aus Laufzeitgründen nicht evaluiert.}
\label{img:accuracy_mb}
\end{center}
\end{figure}

Folgende Beobachtungen wurden gemacht:
\begin{description}
\item[Einschwingphase] Die zu erwartende Einschwingphase ist in \SB\ deutlich erkennbar. Das Modell verbessert sich bis zur zweihundertsten Beobachtung kontinuierlich. Dann beginnt eine Stabilisierung. Die Ergebnisse in \MB\ sind kontraintuitiv. Dort ist die Vorhersagegenauigkeit bis auf die ersten wenigen Beobachtungen höher als zum Ende des Beobachtungszeitraumes. Bei der zweihundersten bis dreihundertsten Beobachtung nähert sie sich sogar 100\,\%. Beide Modelle stabilisieren sich jedoch nach einer gewissen Zeit.

Vermutlich ist das Verhalten der beobachteten Nutzer nicht stationär. Zu Beginn des Beobachtungszeitraumes von \MB\ wurden nur einige wenige Zustände relativ vorhersehbar besucht. Nach einiger Zeit folgte ein anderes, schwerer vorhersagbares Bewegungsmuster, welches zum Abfall und Stabilisierung der Genauigkeit führte.
\item[Vorhersagegenauigkeit]  \SB\ erreicht eine durchschnittliche Vorhersagegenauigkeit von ca.~45\,\%, bei \MB\ beträgt sie ungefähr 62\,\%.
\item[Laufzeit]
\end{description}


Diskussion der Ergebnisse
\begin{itemize}
\item Modellkomplexität zu hoch -> unterbestimmt
\item Anzahl parameter zu hoch -> Laufzeitschwierigkeiten bei 3. Ordnung
\end{itemize}

\newpage

\section{Schlussbetrachtung}

\begin{description}
\item[Zusammenfassung] die wichtigsten Ergebnisse der Arbeit werden zusammengefasst
\item[Kritische Würdigung und Ausblick] Erläuterung der Schwächen und Grenzen der (Methodik der) Arbeit. Durch welche Verbesserungen und weiteren Schritte kann diesen Schwächen entgegengewirkt werden? Ggf. Ausblick auf weitere offene Forschungsfragen bezüglich der Arbeit.
\end{description} 

Kritik/Erweiterungsmöglichkeiten:
\begin{itemize}
\item mehr Daten -> Modelle unterbestimmt
\item Einbezug weiterer Features (Uhrzeit)
\item GPS und Rastern / Clustering -> HMM
\item Ensemble Learning
\end{itemize}


\newpage

\parskip 12pt %Absatzabstand
\renewcommand{\baselinestretch}{1.00}\normalsize

\printbibliography

\newpage

\renewcommand{\baselinestretch}{1.50}\normalsize

\section*{Anhang A\quad Schätzer für Markov-Ketten}

Gegeben sei eine zeitdiskrete, homogene Markov-Kette $d$-ter Ordnung mit $m$ Zuständen aus dem Zustandsraum $S$. Die Transitionswahrscheinlichkeiten sind im $(d+1)$-dimensionalen Transitionstensor $\mathbf{A} \in \mathbb{R}^{d+1}$ beschrieben. Mit Hilfe beobachteter Zustandsübergänge lassen sich die Transitionswahrscheinlichkeiten schätzen. 

\subsubsection*{Maximum-Likelihood-Schätzung für Markov-Ketten zweiter Ordnung}

\vspace*{-1em}
Seien $A_{ijk} \in \mathbf{A}$ die Übergangswahrscheinlichkeiten $p(x_{t+1} = k|x_{t} = j, x_{t-1} = i)$ von den Zuständen $i$ und $j$ nach $k$. Sei $N_{ijk}$ die Anzahl der in den Daten beobachteten Zustandsübergänge von $i$ und $j$ nach $k$. Dann ist die Likelihood beobachteter Zustandsübergänge gegeben als
\begin{align}
p(x_2,\ldots,x_n | \mathbf{A}) &= \prod\limits_{i = 1}^{m} \prod\limits_{j = 1}^{m} \prod\limits_{k = 1}^{m} \prod\limits_{h = 2}^{n} A_{ijk}^{\mathbb{I}[x_h = k]}\\
&= \prod\limits_{i = 1}^{m}\prod\limits_{j = 1}^{m}\prod\limits_{k = 1}^{m} A_{ijk}^{N_{ij\,k}}\\
&= p(N_{ijk}|\mathbf{A})
\end{align}
Logarithmieren der Likelihood ergibt:
\begin{align}
\log p(N_{ijk}|\mathbf{A}) &= \sum\limits_{i=1}^{m} \sum\limits_{j=1}^{m} \sum\limits_{k=1}^{m} \log A_{ijk}^{N_{ij\,k}}\\
&= \sum\limits_{i=1}^{m} \sum\limits_{j=1}^{m} \sum\limits_{k=1}^{m} N_{ij\,k} \cdot \log A_{ijk}
\end{align}
Nun muss die Log-Likelihood unter den Nebenbedingungen $\forall i,j\in S : \sum\limits_{k=1}^{m} A_{ijk} = 1$ mit Hilfe der Lagrange-Methode maximiert werden, um den Maximum-Likelihood-Schätzer $\mathbf{\hat A}$ des Transitionstensors zu erhalten. Zunächst wird die Langrangefunktion $L(\mathbf{A}, \mathbf{\lambda})$ aufgestellt und anschließend durch Null-Setzen der partiellen Ableitungen maximiert.
\begin{align}
L(\mathbf{A}, \mathbf{\lambda}) &= \sum\limits_{i=1}^{m} \sum\limits_{j=1}^{m} \sum\limits_{k=1}^{m} N_{ij\,k} \cdot \log A_{ijk} - \sum\limits_{i=1}^{m} \sum\limits_{j=1}^{m} \lambda_{ij} \left(\left(\sum\limits_{k=1}^{m}A_{ijk}\right)-1\right)
\end{align}
\begin{align}
\frac{\partial L(\mathbf{A}, \mathbf{\lambda})}{\partial A_{ijk}} &= \frac{N_{ijk}}{A_{ijk}} - \lambda_{ij}\notag \\
\text{FOC:\quad} \frac{N_{ijk}}{A_{ijk}} - \lambda_{ij} &= 0 \notag \\
A_{ijk} &= \frac{N_{ijk}}{\lambda_{ij}}\label{eq:a_ijk}
\end{align}


\vspace*{-3em}
\begin{align}
\frac{\partial L(\mathbf{A}, \mathbf{\lambda})}{\partial \lambda_{ij}} &= 1- \sum\limits_{k=1}^{m} A_{ijk} \notag \\
\text{FOC:\quad} 1- \sum\limits_{k=1}^{m} A_{ijk} &= 0 \notag \\
1- \sum\limits_{k=1}^{m} \frac{N_{ijk}}{\lambda_{ij}} &= 0 \notag \\
\lambda_{ij} &= \sum\limits_{k=1}^{m} N_{ijk}\label{eq:lambda_ij}
\end{align}
Durch Einsetzen von (\ref{eq:lambda_ij}) in (\ref{eq:a_ijk}) ergibt sich der Schätzer für die Transitionswahrscheinlichkeiten einer Markov-Kette zweiter Ordnung: 
\begin{align}
\hat{A}_{ijk} = \frac{N_{ijk}}{\sum\limits_{k=1}^{m} N_{ijk}}
\end{align}

\subsubsection*{Maximum-Likelihood-Schätzung für Markov-Ketten dritter Ordnung}

\vspace*{-1em}
Seien $A_{ijkl} \in \mathbf{A}$ die Übergangswahrscheinlichkeiten $p(x_{t+1} = l|x_{t} = k, x_{t-1} = j, x_{t-2} = i)$ von den Zuständen $i$, $j$ und $k$ nach $l$. Sei $N_{ijkl}$ die Anzahl der in den Daten beobachteten Zustandsübergänge von $i$, $j$ und $k$ nach $l$. Dann ist die Likelihood beobachteter Zustandsübergänge gegeben als
\begin{align}
p(x_3,\ldots,x_n | \mathbf{A}) &= \prod\limits_{i = 1}^{m} \prod\limits_{j = 1}^{m} \prod\limits_{k = 1}^{m} \prod\limits_{l = 1}^{m} \prod\limits_{h = 3}^{n} A_{ijkl}^{\mathbb{I}[x_h = l]}\\
&= \prod\limits_{i = 1}^{m}\prod\limits_{j = 1}^{m}\prod\limits_{k = 1}^{m} \prod\limits_{l = 1}^{m} A_{ijkl}^{N_{ij\,kl}}\\
&= p(N_{ijkl}|\mathbf{A})
\end{align}
Logarithmieren der Likelihood ergibt:
\begin{align}
\log p(N_{ijkl}|\mathbf{A}) &= \sum\limits_{i=1}^{m} \sum\limits_{j=1}^{m} \sum\limits_{k=1}^{m} \sum\limits_{l=1}^{m} \log A_{ijkl}^{N_{ij\,kl}}\\
&= \sum\limits_{i=1}^{m} \sum\limits_{j=1}^{m} \sum\limits_{k=1}^{m} \sum\limits_{l=1}^{m} N_{ij\,kl} \cdot \log A_{ijkl}
\end{align}
Nun muss die Log-Likelihood unter den Nebenbedingungen $\forall i,j,k\in S : \sum\limits_{l=1}^{m} A_{ijkl} = 1$ mit Hilfe der Lagrange-Methode maximiert werden, um den Maximum-Likelihood-Schätzer $\mathbf{\hat A}$ des Transitionstensors zu erhalten. Zunächst wird die Langrangefunktion $L(\mathbf{A}, \mathbf{\lambda})$ aufgestellt und anschließend durch Null-Setzen der partiellen Ableitungen maximiert.
\begin{align}
L(\mathbf{A}, \mathbf{\lambda}) &= \sum\limits_{i=1}^{m} \sum\limits_{j=1}^{m} \sum\limits_{k=1}^{m} \sum\limits_{l=1}^{m} N_{ij\,kl} \cdot \log A_{ijkl} - \sum\limits_{i=1}^{m} \sum\limits_{j=1}^{m} \sum\limits_{k=1}^{m} \lambda_{ijk} \left(\left(\sum\limits_{l=1}^{m}A_{ijkl}\right)-1\right)
\end{align}

\vspace*{-3em}
\begin{align}
\frac{\partial L(\mathbf{A}, \mathbf{\lambda})}{\partial A_{ijkl}} &= \frac{N_{ijkl}}{A_{ijkl}} - \lambda_{ijk} \notag \\
\text{FOC:\quad} \frac{N_{ijkl}}{A_{ijkl}} - \lambda_{ijk} &= 0 \notag \\
A_{ijkl} &= \frac{N_{ijkl}}{\lambda_{ijk}}\label{eq:a_ijkl}
\end{align}

\vspace*{-3em}
\begin{align}
\frac{\partial L(\mathbf{A}, \mathbf{\lambda})}{\partial \lambda_{ijk}} &= 1- \sum\limits_{l=1}^{m} A_{ijkl} \notag \\
\text{FOC:\quad} 1- \sum\limits_{l=1}^{m} A_{ijkl} &= 0 \notag \\
1- \sum\limits_{l=1}^{m} \frac{N_{ijkl}}{\lambda_{ijk}} &= 0 \notag \\
\lambda_{ijk} &= \sum\limits_{l=1}^{m} N_{ijkl}\label{eq:lambda_ijk}
\end{align}
Durch Einsetzen von (\ref{eq:lambda_ijk}) in (\ref{eq:a_ijkl}) ergibt sich der Schätzer für die Transitionswahrscheinlichkeiten einer Markov-Kette dritter Ordnung: 
\begin{align}
\hat{A}_{ijkl} = \frac{N_{ijkl}}{\sum\limits_{l=1}^{m} N_{ijkl}}
\end{align}

\end{document}

