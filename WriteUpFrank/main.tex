\documentclass[a4paper, 12pt, titlepage, bibtotoc]{scrartcl} %scrartcl für kurze Artikel

\renewcommand*\sectfont{\normalcolor\rmfamily\bfseries}
\renewcommand*\descfont{\rmfamily\bfseries}
\setkomafont{dictum}{\normalfont\normalcolor\rmfamily\small}

\makeatletter% siehe De-TeX-FAQ
\renewcommand*{\toc@heading}{%
  \addsec{\contentsname}% bei scrartcl \addsec statt \addchap
  \@mkboth{\contentsname}{\contentsname}%
}
\makeatother% siehe \makeatletter

\usepackage[ngerman]{babel}
\usepackage[ansinew]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{color}
% \usepackage{courier} % Monospace/Truetype umstellen
\usepackage{enumitem} % \begin{enumerate}[label={\alph*)}] \item \end{enumerate} für a) b) c)...
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{setspace}
\usepackage{ulem}
	\normalem %stellt emph{} wieder auf kursiv, sonst unterstrichen
\usepackage{graphicx}
\graphicspath{{img/}}
\usepackage[hmargin={3cm,3cm}, vmargin={2.5cm, 3.5cm}]{geometry}
% \usepackage{times}
\usepackage{mathptmx}
\usepackage{nicefrac} 	
\usepackage{tikz}
\usepackage{tabularx}
\usepackage{scalefnt}
\usepackage{titlesec}
\titlespacing{\section}{0pt}{*2.5}{*1.5}
\titlespacing{\subsection}{0pt}{*2}{*1}
\titlespacing{\subsubsection}{0pt}{*1}{*0.5}

\tolerance=500

\usepackage{url}
\urlstyle{leo}

\DeclareMathOperator*{\argmax}{\text{arg\,max}}

%\usepackage{hyperref}
\usepackage{csquotes}
\usepackage{parcolumns}

\bibliography{literature}
\usepackage[style=authoryear]{biblatex} 
\addbibresource{literature.bib}

\DefineBibliographyStrings{ngerman}{
    references = {Literaturverzeichnis}
}

\defbibenvironment{bibliography}
{\list{}
{\setlength{\leftmargin}{\bibhang}%
\setlength{\itemindent}{-\leftmargin}%
\setlength{\itemsep}{12px}%
\setlength{\parsep}{\bibparsep}}}
{\endlist}
{\item}

% \renewbibmacro*{cite:year+labelyear}{%
% \iffieldundef{year}
% {}
% {\printtext[bibhyperref]{%
% \mkbibparens{%
% \printfield{year}%
% \printfield{labelyear}}}}}


%%%% Klammern um die Jahreszahl 
% \renewbibmacro*{cite:labelyear+extrayear}{%
% \iffieldundef{labelyear}
% {}
% {\printtext[bibhyperref]{%
% \mkbibparens{\iffieldundef{origyear}{}{\printfield{origyear}\addslash}% <--- added
% \printfield{labelyear}%
% \printfield{extrayear}}}}}
% 
% \renewbibmacro*{date+extrayear}{%
% \iffieldundef{year}
% {}
% {\printtext[parens]{%
% \iffieldundef{origyear}{}{\printfield{origyear}\addslash}%<--- added
% \printdateextra}}}

%Schriftart http://tu-dresden.de/Members/jan.rudl/latex_win/fonts.pdf
%\usepackage[T1]{fontenc}
%\newcommand{\changefont}[3]{
%\fontfamily{#1} \fontseries{#2} \fontshape{#3} \selectfont}

% \setlength{\tabcolsep}{5pt} %colspan
% \renewcommand{\arraystretch}{1.3} %rowspan

\usepackage{parskip}

\begin{document}

\input{inc.title.tex}

% \setcounter{page}{0}\clearpage\newpage
\renewcommand{\baselinestretch}{1.25}\normalsize


\pagenumbering{Roman} \setcounter{page}{2}
\addcontentsline{toc}{section}{Inhaltsverzeichnis}
\tableofcontents

\renewcommand{\baselinestretch}{1.50}\normalsize

\newpage

\addcontentsline{toc}{section}{Abbildungsverzeichnis}
\listoffigures

\newpage

\section*{Abkürzungsverzeichnis}
\addcontentsline{toc}{section}{Abkürzungsverzeichnis}

\begin{tabular}{ll}
CSV & Comma-Separated Value\\
GSM & Global System for Mobile Communications\\
GPS & Global Positioning System\\
ML & Maximum Likelihood\\
UMTS & Universal Mobile Telecommunications System
\end{tabular}

\newpage

\listoftables
\addcontentsline{toc}{section}{Tabellenverzeichnis}

\newpage

\pagenumbering{arabic} \setcounter{page}{1}

\section{Einleitung}

\begin{description}
\item[Problemstellung] Heranführen an das Thema. Warum soll Arbeit geschrieben werden. Offene Frage mit Problembeschreibung.
\item[Zielstellung] Ein oder zwei Sätze zum Ziel.
\item[Methodik und Vorgehensweise] Wie werden Ergebnisse ermittelt? Gliederung der Arbeit in Worten.
\end{description}

Computer sind heutzutage allgegenwärtig. Viele Menschen besitzen mobile Geräte, die in Sachen Rechenleistung stationären Computern nur noch in wenig nachstehen. Der wirtschaftliche Nutzen des sogenannten "`ubiquitous computing"' ist vielseitig. So könnten beispielsweise Restaurantbesitzer besondere Mittagsangebote auf das Smartphone der potenziellen Kunden senden, die noch unentschlossen vor ihrem Lokal stehen. Könnte man vorhersehen, wo sich die Anwender zukünftig hinbewegen, so könnten Angebote schon im Vorfeld unterbreitet oder Informationen verschickt werden.

Ziel des Projekts ist es, eine Handyanwendung zu programmieren, welche die nötigen Daten für eine verlässliche Positionsvorhersage sammelt, und diese auszuwerten. Somit soll untersucht werden, mit welcher Genauigkeit Bewegungen von Menschen vorhergesagt werden können. Im Rahmen dieser Arbeit liegt der Fokus auf der Positionsvorhersage.

Methodik: Java / AndroidApp, R

Related Work...

Im ersten Abschnitt ...

\section{Methoden}
\subsection{Datenerhebung und -vorerarbeitung}
\label{subsec:data_collection}

Um Daten zur anschließenden Auswertung zu sammeln, wurde die Android-Anwendung \emph{AndroidDataCollection}\footnote{Quellcode und Dokumentation finden sich auf \emph{https://github.com/FRSB/AndroidDataCollection}.} entwickelt. Auf dem Mobiltelefon installiert, zeichnet sie minütlich Daten verschiedener Sensoren und Schnittstellen auf und speichert diese lokal in einer Datei. Für die in Abschnitt~\ref{subsec:analysis} beschriebenen Analysen sind folgende Informationen relevant: (1) Mobilfunkzellen-ID der aktuell verwendeten Zelle (GSM oder UMTS) und (2) Position des Mobiltelefons\footnote{Die Positionsbestimmung findet hierarchisch statt. Zunächst wird versucht, die ungefähre Position über die aktuell verwendete Mobilfunkzelle zu ermitteln. Falls ein Drahtlosnetzwerk zur Verfügung steht über das hinreichend genaue Positionsdaten verfügbar sind, wird die Position aktualisiert. Sollte das GPS-Signal anliegen und stark genug sein, überschreibt es die ungefähren Positionsdaten. So wird der API die bestmögliche Position übergeben. Nähere Informationen finden sich im Android Developers API Guide unter \emph{http://developer.android.com/guide/topics/location/strategies.html}.}.

Nach einer gewissen Zeit wird das Mobiltelefon über USB mit dem Computer verbunden und die gesammelten Daten in Form einer CSV-Datei übertragen. Damit aus den minütlich aufgezeichneten Positionsdaten eine Bewegungsvorhersage möglich ist, müssen ein paar Datenaufbereitungen und -transformationen stattfinden. So werden zunächst fehlerhaft aufgezeichnete Datensätze und Aufzeichnungen ohne bestimmbare Mobilfunkzellen-ID entfernt. Anschließend folgen zwei Vorverarbeitungsschritte unabhängig voneinander: Extrahieren der Bewegungen und Schätzung der Mobilfunkzellenpositionen.

\begin{description}
\item[Extrahieren der Bewegungen.] Hierfür werden die aufgezeichneten Zellen in zeitlich korrekter Reihenfolge hintereinander gereiht. Aufeinanderfolgende Aufzeichnungen, bei denen sich die Mobilfunkzellen-ID nicht ändert, werden entfernt. So bleibt eine Folge von Zellenübergängen übrig, die später zur Vorhersage verwendet werden kann.
\item[Schätzung der Mobilfunkzellenpositionen.] Um die aufgezeichneten Bewegungen visualisieren zu können, wird zu jeder gesehenen Mobilfunkzelle eine ungefähre Position bestimmt. Dies geschieht, indem die Daten nach Mobilfunkzelle gruppiert und anschließend die jeweils gemessenen Positionen des Mobiltelefons gemittelt werden. So entsteht eine Zuordnung von Mobilfunkzellen zu Positionen.
\end{description}

\subsection{Datenanalyse}
\label{subsec:analysis}

\subsubsection*{Modellbildung}

Die Bewegungen eines Mobiltelefonnutzers werden als zeitdiskreter stochastischer Prozess modelliert. Sei der Beobachtungszeitraum $T = \{0,\ldots,n\}$ und der Zustandsraum $S = \{1, \ldots, m\}$. Ein Nutzer $u$ befindet sich zum Zeitpunkt $t \in T$ im Zustand $x_t \in S$. Ein Zustand entspricht der Mobilfunkzelle, an welcher der Nutzer angemeldet ist. Eine Bewegung von einer Mobilfunkzelle zur nächsten entspricht somit einer diskreten Zustandsänderung von $x_t$ zu $x_{t+1}$. Jeder Zustandsänderung wird eine Wahrscheinlichkeit in Abhängigkeit der vergangenen Zustände zugeordnet. Solche Modelle werden Markov-Modelle genannt.\footcite[Vgl.][S.~607~ff.]{bishop2006pattern} In den folgenden Absätzen sollen die zur Vorhersage verwendeten Modelle vorgestellt werden.

Will man die nächste Position eines Nutzers vorhersagen, erscheint es nützlich, dies in Abhängigkeit der aktuellen Position zu tun. Das entstehende Markov-Modell ist eine Markov-Kette erster Ordnung. Unter der Annahme stationärer Übergangswahrscheinlichkeiten\footnote{Hängt die Wahrscheinlichkeit $p(x_{t+1}|x_{t})$ für den Übergang von $x_t$ nach $x_{t+1}$ nicht von $t$ ab, spricht man von sogenannten stationären Übergangswahrscheinlichkeiten. Es spielt für den Übergang also keine Rolle an welchem Zeitpunkt er stattfindet. Markov-Ketten mit stationären Übergangswahrscheinlichkeiten nennt man homogen. Vgl.~hierzu \textcite{ouvrard2009probabilites}, S.~411.} lässt sich das Modell mit Hilfe eines Transitionsdiagramms und der zugehörigen Transitionsmatrix beschreiben. Exemplarisch soll für die folgenden Erklärungen ein Modell mit drei Zuständen betrachtet werden. Das Transitionsdiagramm ist in Abbildung~\ref{img:transitions} dargestellt. Die zugehörigen Übergangswahrscheinlichkeiten werden in einer Transitionsmatrix der Form
\begin{equation}
\mathbf{A}=\begin{bmatrix}
A_{11} & A_{12} & A_{13} \\
A_{21} & A_{22} & A_{23} \\
A_{31} & A_{32} & A_{33}
\end{bmatrix}
\end{equation}
dargestellt, wobei $A_{ij} = p(x_{t+1} = j | x_t=i)$ der Wahrscheinlichkeit für den Zustandsübergang von $x=i$ nach $x=j$ entspricht. Zusätzlich müssen die Übergangswahrscheinlichkeiten in $\mathbf{A}$ zeilenweise die Bedingungen an eine Wahrscheinlichkeitsverteilung erfüllen:
\begin{equation}
\forall i,j \in S: A_{ij} \geq 0,
\end{equation}
\begin{equation}
\forall i\in S: \sum_{j\in S} A_{ij} = 1.
\end{equation}

\begin{figure}[t]
	\centering
	\begin{tabular}{@{}r@{}}
		\scalebox{.6}{%
			\scalefont{2}
			\input{img/transition_chart.tex}
			}\\
		\footnotesize Quelle: In Anlehnung an \textcite{bishop2006pattern}, S.~611
	\end{tabular}

	\caption{Transitionsdiagramm für eine Markov-Kette erster Ordnung. Die Wahrscheinlichkeiten für einen Zustandsübergang von $x=i$ nach $x=j$ werden durch das Element $A_{ij}$ der zugehörigen Transitionsmatrix ausgedrückt.}
	\label{img:transitions}
\end{figure}

Das gerichtete graphische Modell einer Markov-Kette ist in Abbildung~\ref{img:graphical_model} dargestellt. Die Verbundverteilung der beobachteten Zustände $p(x_0, \ldots x_n)$ faktorisiert entsprechend der Unabhängigkeitsannahmen in
\begin{equation}
p(x_0, \ldots, x_n) = p(x_0) \prod\limits_{t=1}^{n}p(x_t | x_{t-1}).
\end{equation}
Die Parameter des Modells sind zum einen die Transitionsmatrix $\mathbf{A}$, welche alle bedingten Wahrscheinlichkeiten enthält, sowie zum anderen der Vektor $\vec \pi$  mit $\pi_i = p(x_0 = i)$, welcher die Wahrscheinlichkeiten für die Startzustände angibt.


\begin{figure}
	\centering
	\scalebox{.8}{%
	\scalefont{2}
	\input{img/graphical_model.tex}
	}
	\caption{Graphisches Modell einer Markov-Kette erster Ordnung. Der Zustand zum nachfolgenden Zeitpunkt hängt nur vom aktuellen Zustand ab.}
	\label{img:graphical_model}
\end{figure}

Markov-Ketten erster Ordnung treffen starke Unabhängigkeitsannahmen. Möchte man bei der Vorhersage nicht nur die direkte Vergangenheit betrachten, sondern weiter zurückblicken, müssen diese Annahmen abgeschwächt werden. Es ergeben sich Markov-Ketten höherer Ordnung. Entsprechend erhöht sich die Anzahl der Parameter des Modells. So berücksichtigt eine Markov-Kette zweiter Ordnung beim Vorhersagen von $x_{t+1}$ die Zustände $x_{t}$ und $x_{t-1}$. Die stationären Übergangswahrscheinlichkeiten einer Markov-Kette $d$-ter Ordnung können in einem $d+1$-dimensionalen Tensor repräsentiert werden.

\subsubsection*{Parameterschätzung und Vorhersage}

Zur Schätzung der Transitionsmatrix homogener Markov-Ketten erster Ordnung kann ein Maximum-Likelihood-Schätzer (ML) verwendet werden. Sei $N_{ij}$ die Anzahl der beobachteten Zustandsübergänge von Zustand $i$ nach Zustand $j$, dann ist der ML-Schätzer $\mathbf{\hat A}$ für die Transitionsmatrix gegeben als\footnote{Vgl.~\cite{murphy2012machine},~S.~593}
\begin{equation}
\hat A_{ij} = \frac{N_{ij}}{\sum_{j}N_{ij}}.
\end{equation}
Bei gegebenem Zustand $x_{t} = i$ kann zur Vorhersage des nächsten Zustandes $\hat x_{t+1}$ der mit der größten Transitionswahrscheinlichkeit von $j$ ausgehend gewählt werden:
\begin{equation}
\hat x_{t+1} = \argmax_j\ \hat A_{ij},\quad x_{t} = i
\end{equation}
Der Parameter $\vec \pi = p(x_0)$ ist bei der Vorhersage unerheblich, sofern bereits eine Position bekannt ist. Er wird deshalb nicht geschätzt.

Die Schätzer für die Transitionswahrscheinlichkeiten der Markov-Ketten höherer Ordnung sowie die zugehörige Vorhersagegleichung sind in Tabelle~\ref{tab:markov} dargestellt. Die Anzahl der Parameter (Elemente der Transitionsmatrix bzw. des Transitionstensors) wächst mit steigender Ordnung exponentiell.\footnote{Je weiter in die Vergangenheit geschaut wird, desto mehr Kombinationen von Zustandsübergängen gibt es. Da für jede Kombination die Summe der Übergangswahrscheinlichkeiten zu 1 summieren muss, werden nur $m^k \cdot (m-1)$ und nicht $m^{k+1}$ Parameter benötigt. Die letzte Wahrscheinlichkeit kann jeweils errechnet werden.} Die Herleitung der Schätzer findet sich in Anhang A.

\renewcommand{\arraystretch}{1.2}
\begin{table}[t]
\centering
\begin{tabular}{m{3cm}m{3.5cm}m{3cm}m{3.6cm}}
\textbf{Modell} & \textbf{Anzahl Parameter} & \textbf{Schätzer} & \textbf{Vorhersage}\\
\hline
Markov-Kette erster Ordnung & $m \cdot (m - 1)$ & $\hat A_{ij} = \frac{N_{ij}}{\sum_{j}N_{ij}}$ & $\hat x_{t+1} = \argmax_j\ \hat A_{ij}$\\
Markov-Kette zweiter Ordnung & $m^2 \cdot (m - 1)$ & $\hat A_{ijk} = \frac{N_{ijk}}{\sum_{k}N_{ijk}}$ & $\hat x_{t+1} = \argmax_k\ \hat A_{ijk}$\\
Markov-Kette dritter Ordnung & $m^3 \cdot (m - 1)$ & $\hat A_{ijkl} = \frac{N_{ijkl}}{\sum_{l}N_{ijkl}}$ & $\hat x_{t+1} = \argmax_l\ \hat A_{ijkl}$
\end{tabular}
\caption{Eigenschaften von Markov-Ketten verschiedener Ordnung}
\label{tab:markov}
\end{table}

\section{Experimente}

\subsection{Datensätze}

\newcommand{\SB}{SB}
\newcommand{\MB}{MB}

Während des Projekts wurden mit Hilfe der in Abschnitt~\ref{subsec:data_collection} vorgestellten Software von zwei freiwilligen Mobilfunknutzern innerhalb eines Monats Daten gesammelt. Tabelle~\ref{tab:datasets} zeigt die Anzahl der besuchten Mobilfunkzellen (Zustände), die Anzahl der beobachteten Zustandsübergänge und die Häufigkeitsverteilung der beobachteten Zustände der zwei gewonnenen Datensätze nach der Vorverarbeitung. Datensatz \SB\ beinhaltet weniger Zustände und Beobachtungen als Datensatz \MB, ist jedoch auch weniger steil ($\omega_{\text{\SB}} = 22{,}4$ und  $\omega_{\text{\MB}} = 69{,}13$).\footnote{Die relative Kurtosis $\omega$ einer Verteilung ist ein Maß für die Steilheit. Eine sehr steile Verteilung weist die Wahrscheinlichkeitsmasse hauptsächlich einigen wenigen, extremen Ereignissen zu. Die relative Kurtosis der Standardnormalverteilung beträgt $\omega_{\mathcal N(0,1)} = 3$. Näheres hierzu findet sich in \textcite{assenmacher2003deskriptive},~S.~114~ff.}

\renewcommand{\arraystretch}{1.4}
\newcolumntype{R}[1]{>{\raggedright\arraybackslash}m{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash}m{#1}}
\begin{table}[t]
\centering
\begin{tabular}{m{2cm}C{2.5cm}C{3cm}C{5cm}@{}}
\textbf{Datensatz} & \textbf{Anzahl Zustände} & \textbf{Anzahl Beobachtunge\-n} & \textbf{Häufigkeitsverteilung\newline der Zustände}\\
\hline
\SB & 78 & 603 & \includegraphics*[width=5cm, trim=2cm 2cm 1.5cm 1cm]{sb_cell_table}\\
\MB & 156 & 1533 &  
\includegraphics*[width=5cm, trim=2cm 2cm 1.5cm 1.5cm]{mb_cell_table}
\end{tabular}
\caption{Metadaten der zwei gesammelten Datensätze}
\label{tab:datasets}
\end{table}

Visualisierung der Zellen ...

\begin{figure}[p]
\begin{center}
\includegraphics*[width=1\linewidth]{cell_locations}
\caption{Locations}
\label{img:locations}
\end{center}
\end{figure} 

\begin{figure}[p]
\begin{center}
\includegraphics*[width=.9\linewidth]{map.png}
\caption{Karte}
\label{img:map}
\end{center}
\end{figure} 

\subsection{Untersuchung der Vorhersagegenauigkeit}

Markov Ketten angewendet

Evaluation erklären

\begin{figure}[p]
\begin{center}
\includegraphics*[width=.9\linewidth]{prediction_accuracy_sb}
\caption{Genauigkeit}
\label{img:accuracy_sb}
\end{center}
\end{figure}

\begin{figure}[p]
\begin{center}
\includegraphics*[width=.9\linewidth]{prediction_accuracy_mb}
\caption{Genauigkeit}
\label{img:accuracy_mb}
\end{center}
\end{figure}

Diskussion der Ergebnisse
\begin{itemize}
\item Modellkomplexität zu hoch -> unterbestimmt
\item Anzahl parameter zu hoch -> Laufzeitschwierigkeiten bei 3. Ordnung
\end{itemize}

\section{Schlussbetrachtung}

\begin{description}
\item[Zusammenfassung] die wichtigsten Ergebnisse der Arbeit werden zusammengefasst
\item[Kritische Würdigung und Ausblick] Erläuterung der Schwächen und Grenzen der (Methodik der) Arbeit. Durch welche Verbesserungen und weiteren Schritte kann diesen Schwächen entgegengewirkt werden? Ggf. Ausblick auf weitere offene Forschungsfragen bezüglich der Arbeit.
\end{description} 

Kritik/Erweiterungsmöglichkeiten:
\begin{itemize}
\item mehr Daten -> Modelle unterbestimmt
\item Einbezug weiterer Features (Uhrzeit)
\item GPS und Rastern / Clustering -> HMM
\item Ensemble Learning
\end{itemize}


\newpage

\parskip 12pt %Absatzabstand
\renewcommand{\baselinestretch}{1.50}\normalsize

\printbibliography

\section*{Anhang A\quad Schätzer für Markov-Ketten}

Gegeben sei eine zeitdiskrete, homogene Markov-Kette $d$-ter Ordnung mit $m$ Zuständen aus dem Zustandsraum $S$. Die Transitionswahrscheinlichkeiten sind im $(d+1)$-dimensionalen Transitionstensor $\mathbf{A} \in \mathbb{R}^{d+1}$ beschrieben. Mit Hilfe beobachteter Zustandsübergänge lassen sich die Transitionswahrscheinlichkeiten schätzen. 

\subsubsection*{Maximum-Likelihood-Schätzung für Markov-Ketten zweiter Ordnung}

Seien $A_{ijk} \in \mathbf{A}$ die Übergangswahrscheinlichkeiten $p(x_{t+1} = k|x_{t} = j, x_{t-1} = i)$ von den Zuständen $i$ und $j$ nach $k$. Sei $N_{ijk}$ die Anzahl der in den Daten beobachteten Zustandsübergänge von $i$ und $j$ nach $k$. Dann ist die Likelihood beobachteter Zustandsübergänge gegeben als [CITATION NEEDED]
\begin{align}
p(x_2,\ldots,x_n | \mathbf{A}) &= \prod\limits_{i = 1}^{m} \prod\limits_{j = 1}^{m} \prod\limits_{k = 1}^{m} \prod\limits_{h = 2}^{n} A_{ijk}^{\mathbb{I}[x_h = k]}\\
&= \prod\limits_{i = 1}^{m}\prod\limits_{j = 1}^{m}\prod\limits_{k = 1}^{m} A_{ijk}^{N_{ij\,k}}\\
&= p(N_{ijk}|\mathbf{A})
\end{align}
Logarithmieren der Likelihood ergibt:
\begin{align}
\log p(N_{ijk}|\mathbf{A}) &= \sum\limits_{i=1}^{m} \sum\limits_{j=1}^{m} \sum\limits_{k=1}^{m} \log A_{ijk}^{N_{ij\,k}}\\
&= \sum\limits_{i=1}^{m} \sum\limits_{j=1}^{m} \sum\limits_{k=1}^{m} N_{ij\,k} \cdot \log A_{ijk}
\end{align}
Nun muss die Log-Likelihood unter den Nebenbedingungen $\forall i,j\in S : \sum\limits_{k=1}^{m} A_{ijk} = 1$ mit Hilfe der Lagrange-Methode maximiert werden, um den Maximum-Likelihood-Schätzer $\mathbf{\hat A}$ des Transitionstensors zu erhalten. Zunächst wird die Langrangefunktion $L(\mathbf{A}, \mathbf{\lambda})$ aufgestellt und anschließend durch Null-Setzen der partiellen Ableitungen maximiert.
\begin{align}
L(\mathbf{A}, \mathbf{\lambda}) &= \sum\limits_{i=1}^{m} \sum\limits_{j=1}^{m} \sum\limits_{k=1}^{m} N_{ij\,k} \cdot \log A_{ijk} - \sum\limits_{i=1}^{m} \sum\limits_{j=1}^{m} \lambda_{ij} \left(\left(\sum\limits_{k=1}^{m}A_{ijk}\right)-1\right)
\end{align}
\begin{align}
\frac{\partial L(\mathbf{A}, \mathbf{\lambda})}{\partial A_{ijk}} &= \frac{N_{ijk}}{A_{ijk}} - \lambda_{ij}\\
\text{FOC:\quad} \frac{N_{ijk}}{A_{ijk}} - \lambda_{ij} &= 0\\
A_{ijk} &= \frac{N_{ijk}}{\lambda_{ij}}
\end{align}
\begin{align}
\frac{\partial L(\mathbf{A}, \mathbf{\lambda})}{\partial \lambda_{ij}} &= 1- \sum\limits_{k=1}^{m} A_{ijk}\\
\text{FOC:\quad} 1- \sum\limits_{k=1}^{m} A_{ijk} &= 0\\
s
\end{align}

\section*{Anhang}

\begin{itemize}
\item im folgenden am Beispiel Markov-Ketten erster Ordnung
\item Zeitdiskrete Markov-Kette
\item Zustandsraum $S \in \{1, 2, 3, \ldots\}$
\item homogene Markov-Kette: $p_{ij}(t)=p_{ij}$ (stationäre Übergangswahrscheinlichkeiten)
\item $P = p_{ij}$ ist Übergangsmatrix ($p_{ij} \geq 0$, $\sum_{j_\in S} p_{ij} = 1$)
\item Stochastischer Prozess $X=\{X_t, t\in N_0\}$, $S$ diskret heißt Markov-Kette $p$-ter Ordnung, gdw. $\forall i_0, i_1, \ldots, i_{t+1} \in S, t \geq p+1$ gilt\\
$P(X_{t+1} = i_{t+1} | X_t=i_t, \ldots, X_{t-p+1} = i_{t-p+1}, \ldots, X_0 = i_0)$\\
$= P(X_{t+1} = i_{t+1} | X_t=i_t, \ldots, X_{t-p+1} = i_{t-p+1})$ (Markov-Eigenschaft)
\item Inferenz bei homogenen Markov-Ketten erster Ordnung $\hat p_{ij} = \frac{n_{ij}}{n_{i}}$, mit $n_{ij}$ als Anzahl beobachteter Übergänge von $i$ nach $j$.
\item \textbf{Maximum Likelihood erster Ordnung}
\begin{enumerate}
%\item $ \displaystyle L(p_0,P|X) = \prod_{t=1}^T L(x_t|x_{t-1}, P) \cdot L(x_0|p_0)$
%\item $ \displaystyle L(p_0,P) = P(X_0 = i_0, \ldots, X_T = i_T)$
%\item $ \displaystyle L(P) =p_{i_0}\cdot p_{i_0i_1}\cdot \ldots \cdot p_{i_{T-1}i_T}$
\item Likelihood:\\
$ \displaystyle L(P) = \prod_{i=1}^m\prod_{j=1}^m p_{ij}^{n_{ij}},\quad i,j \in \text{Zustandsraum}$
% Problem ist noch erster und letzter Zustand!
\item Log-Likelihood:\\
$ \displaystyle l(P) = \sum_{i=1}^m\sum_{j=1}^m n_{ij} \cdot \ln p_{ij},\quad s.t.\ \forall i: \sum_{j=1}^m p_{ij}=1$
\item $ \displaystyle \mathcal L(P, \lambda_1, \ldots, \lambda_m) = \sum_{i=1}^m \sum_{j=1}^m n_{ij} \ln(p_{ij}) - \sum_{i=1}^m \lambda_i \left(\left(\sum_{j=1}^m p_{ij}\right) - 1 \right)$
\item $ \displaystyle \frac{\partial \mathcal L}{\partial p_{ij}} = \frac{n_{ij}}{p_{ij}} - \lambda_i$
\item FOC: $ \displaystyle \frac{n_{ij}}{p_{ij}} - \lambda_i = 0\quad \Leftrightarrow \quad p_{ij} = \frac{n_{ij}}{\lambda_i}$
\item $ \displaystyle \frac{\partial \mathcal L}{\partial \lambda_{i}} = 1 - \sum_{j=1}^m p_{ij}$
\item FOC: $ \displaystyle 1 - \sum_{j=1}^m p_{ij} = 0$
\item $ \displaystyle 1 - \sum_{j=1}^m \frac{n_{ij}}{\lambda_i} = 0$
\item $ \displaystyle \sum_{j=1}^m n_{ij} = \lambda_i$
\item $ \displaystyle \hat p_{ij} = \frac{n_{ij}}{\sum_{j=1}^m n_{ij}}$
\end{enumerate}
\end{itemize}


\end{document}

